# predict the new instances
resPredictIns2 = predictIns(ls = lsMods, x = testDs)
View(resPredictIns2)
View(resPredictIns2)
# Part 1 - learning the model
randomForestMods = function(x, t, n, d) {
# x is training data
# t is number of trees to build
# n is number of instances to select for each tree
# d is number of attributes to use
ls = list() # rpart models
for (idx in 1:t) {
# randomly selected with replacement
xSample = x[sample(nrow(x), n, replace = TRUE),]
# attributes randomly selected without replacement
a = sample(names(x)[-length(names(x))], d, replace = FALSE)
# a = sort(a)
print(a)
# build formula
frm = paste0(names(x)[length(names(x))], "~")
for (j in 1:length(a)) {
frm = paste0(frm, a[j], "+")
}
frm = substr(frm, 1, nchar(frm)-1) # remove last character
# build model
a = append(a, names(x)[length(names(x))])
mod = rpart(frm, xSample[, a])
# append to result ls
ls[[idx]] = mod
}
return(ls)
}
# Part 2 - predicting new instances
predictIns = function(ls, x) {
# ls is the list of random forest models
# x is the test data
# Store the prediction in data frame
predsDf = data.frame(matrix(ncol = length(ls), nrow = nrow(x)))
cols = c()
for (i in 1:length(ls)) {
cols = c(cols, paste("mod", i))
}
colnames(predsDf) = cols
# perform predictions
for(i in 1:length(ls)) {
pred = predict(ls[[i]], x, type="vector")
predsDf[i] = pred
}
# label predictions
for(i in 1:ncol(predsDf)) {
ind = predsDf[, i] <= 0.5
predsDf[ind, i] = -1
predsDf[!ind, i] = 1
}
# calculate majority
output = rowSums(predsDf)
output = sign(output)
# add output column to predictions data frame
predsDf["output"] = output
return(predsDf)
}
# load the data set
trainDs = read.table("hw06dataTrain.txt", header = TRUE)
testDs = read.table("hw06dataTest.txt", header = TRUE)
# get the models
lsMods = randomForestMods(x = trainDs, t = 21, n = 3000, d = 3)
# predict the new instances
resPredictIns2 = predictIns(ls = lsMods, x = testDs)
# Part 1 - learning the model
randomForestMods = function(x, t, n, d) {
# x is training data
# t is number of trees to build
# n is number of instances to select for each tree
# d is number of attributes to use
ls = list() # rpart models
for (idx in 1:t) {
# randomly selected with replacement
xSample = x[sample(nrow(x), n, replace = TRUE),]
# attributes randomly selected without replacement
a = sample(names(x)[-length(names(x))], d, replace = FALSE)
# a = sort(a)
print(a)
# build formula
frm = paste0(names(x)[length(names(x))], "~")
for (j in 1:length(a)) {
frm = paste0(frm, a[j], "+")
}
frm = substr(frm, 1, nchar(frm)-1) # remove last character
# build model
a = append(a, names(x)[length(names(x))])
mod = rpart(frm, xSample[, a])
# append to result ls
ls[[idx]] = mod
}
return(ls)
}
# Part 2 - predicting new instances
predictIns = function(ls, x) {
# ls is the list of random forest models
# x is the test data
# Store the prediction in data frame
predsDf = data.frame(matrix(ncol = length(ls), nrow = nrow(x)))
cols = c()
for (i in 1:length(ls)) {
cols = c(cols, paste("mod", i))
}
colnames(predsDf) = cols
# perform predictions
for(i in 1:length(ls)) {
pred = predict(ls[[i]], x, type="vector")
predsDf[i] = pred
}
# label predictions
for(i in 1:ncol(predsDf)) {
ind = predsDf[, i] <= 0.5
predsDf[ind, i] = -1
predsDf[!ind, i] = 1
}
# calculate majority
sum = rowSums(predsDf)
output = sign(sum)
# add sum, output column to predictions data frame
predsDf["sum"] = sum
predsDf["output"] = output
return(predsDf)
}
# load the data set
trainDs = read.table("hw06dataTrain.txt", header = TRUE)
testDs = read.table("hw06dataTest.txt", header = TRUE)
# get the models
lsMods = randomForestMods(x = trainDs, t = 21, n = 3000, d = 3)
# predict the new instances
resPredictIns2 = predictIns(ls = lsMods, x = testDs)
# Part 1 - learning the model
randomForestMods = function(x, t, n, d) {
# x is training data
# t is number of trees to build
# n is number of instances to select for each tree
# d is number of attributes to use
ls = list() # rpart models
for (idx in 1:t) {
# randomly selected with replacement
xSample = x[sample(nrow(x), n, replace = TRUE),]
# attributes randomly selected without replacement
a = sample(names(x)[-length(names(x))], d, replace = FALSE)
# a = sort(a)
# build formula
frm = paste0(names(x)[length(names(x))], "~")
for (j in 1:length(a)) {
frm = paste0(frm, a[j], "+")
}
frm = substr(frm, 1, nchar(frm)-1) # remove last character
print(frm)
# build model
a = append(a, names(x)[length(names(x))])
mod = rpart(frm, xSample[, a])
# append to result ls
ls[[idx]] = mod
}
return(ls)
}
# Part 2 - predicting new instances
predictIns = function(ls, x) {
# ls is the list of random forest models
# x is the test data
# Store the prediction in data frame
predsDf = data.frame(matrix(ncol = length(ls), nrow = nrow(x)))
cols = c()
for (i in 1:length(ls)) {
cols = c(cols, paste("mod", i))
}
colnames(predsDf) = cols
# perform predictions
for(i in 1:length(ls)) {
pred = predict(ls[[i]], x, type="vector")
predsDf[i] = pred
}
# label predictions
for(i in 1:ncol(predsDf)) {
ind = predsDf[, i] <= 0.5
predsDf[ind, i] = -1
predsDf[!ind, i] = 1
}
# calculate majority
sum = rowSums(predsDf)
output = sign(sum)
# add sum, output column to predictions data frame
predsDf["sum"] = sum
predsDf["output"] = output
return(predsDf)
}
# load the data set
trainDs = read.table("hw06dataTrain.txt", header = TRUE)
testDs = read.table("hw06dataTest.txt", header = TRUE)
# get the models
lsMods = randomForestMods(x = trainDs, t = 21, n = 3000, d = 3)
# predict the new instances
resPredictIns2 = predictIns(ls = lsMods, x = testDs)
# Part 1 - learning the model
randomForestMods = function(x, t, n, d) {
# x is training data
# t is number of trees to build
# n is number of instances to select for each tree
# d is number of attributes to use
ls = list() # rpart models
for (idx in 1:t) {
# randomly selected with replacement
xSample = x[sample(nrow(x), n, replace = TRUE),]
# attributes randomly selected without replacement
a = sample(names(x)[-length(names(x))], d, replace = FALSE)
# a = sort(a)
# build formula
frm = paste0(names(x)[length(names(x))], "~")
for (j in 1:length(a)) {
frm = paste0(frm, a[j], "+")
}
frm = substr(frm, 1, nchar(frm)-1) # remove last character
print(frm)
# build model
a = append(a, names(x)[length(names(x))])
mod = rpart(frm, xSample[, a])
# append to result ls
ls[[idx]] = mod
}
return(ls)
}
# Part 2 - predicting new instances
predictIns = function(ls, x) {
# ls is the list of random forest models
# x is the test data
# Store the prediction in data frame
predsDf = data.frame(matrix(ncol = length(ls), nrow = nrow(x)))
cols = c()
for (i in 1:length(ls)) {
cols = c(cols, paste("mod", i))
}
colnames(predsDf) = cols
# perform predictions
for(i in 1:length(ls)) {
pred = predict(ls[[i]], x, type="vector")
predsDf[i] = pred
}
# label predictions
for(i in 1:ncol(predsDf)) {
ind = predsDf[, i] <= 0.5
predsDf[ind, i] = -1
predsDf[!ind, i] = 1
}
# calculate majority
sum = rowSums(predsDf)
output = sign(sum)
# add sum, output column to predictions data frame
predsDf["sum"] = sum
predsDf["output"] = output
return(predsDf)
}
# load the data set
trainDs = read.table("hw06dataTrain.txt", header = TRUE)
testDs = read.table("hw06dataTest.txt", header = TRUE)
# get the models
lsMods = randomForestMods(x = trainDs, t = 21, n = 3000, d = 3)
# predict the new instances
resPredictIns2 = predictIns(ls = lsMods, x = testDs)
print(resPredictIns2["output"])
# Part 1 - learning the model
randomForestMods = function(x, t, n, d) {
# x is training data
# t is number of trees to build
# n is number of instances to select for each tree
# d is number of attributes to use
ls = list() # rpart models
for (idx in 1:t) {
# randomly selected with replacement
xSample = x[sample(nrow(x), n, replace = TRUE),]
# attributes randomly selected without replacement
a = sample(names(x)[-length(names(x))], d, replace = FALSE)
# a = sort(a)
# build formula
frm = paste0(names(x)[length(names(x))], "~")
for (j in 1:length(a)) {
frm = paste0(frm, a[j], "+")
}
frm = substr(frm, 1, nchar(frm)-1) # remove last character
print(frm)
# build model
a = append(a, names(x)[length(names(x))])
mod = rpart(frm, xSample[, a])
# append to result ls
ls[[idx]] = mod
}
return(ls)
}
# Part 2 - predicting new instances
predictIns = function(ls, x) {
# ls is the list of random forest models
# x is the test data
# Store the prediction in data frame
predsDf = data.frame(matrix(ncol = length(ls), nrow = nrow(x)))
# set the column names
cols = c()
for (i in 1:length(ls)) {
cols = c(cols, paste("mod", i))
}
colnames(predsDf) = cols
# perform predictions
for(i in 1:length(ls)) {
pred = predict(ls[[i]], x, type="vector")
predsDf[i] = pred
}
# label predictions
for(i in 1:ncol(predsDf)) {
ind = predsDf[, i] <= 0.5
predsDf[ind, i] = -1
predsDf[!ind, i] = 1
}
# calculate majority vote
sum = rowSums(predsDf)
output = sign(sum)
# add sum, output column to predictions data frame
predsDf["sum"] = sum
predsDf["output"] = output
return(predsDf)
}
# load the data set
trainDs = read.table("hw06dataTrain.txt", header = TRUE)
testDs = read.table("hw06dataTest.txt", header = TRUE)
# get the models
lsMods = randomForestMods(x = trainDs, t = 21, n = 3000, d = 3)
# predict the new instances
resPredictIns2 = predictIns(ls = lsMods, x = testDs)
print(resPredictIns2)
View(resPredictIns)
View(resPredictIns)
View(resPredictIns2)
View(resPredictIns2)
# Part 1 - learning the model
randomForestMods = function(x, t, n, d) {
# x is training data
# t is number of trees to build
# n is number of instances to select for each tree
# d is number of attributes to use
ls = list() # rpart models
for (idx in 1:t) {
# randomly selected with replacement
xSample = x[sample(nrow(x), n, replace = TRUE),]
# attributes randomly selected without replacement
a = sample(names(x)[-length(names(x))], d, replace = FALSE)
# a = sort(a)
# build formula
frm = paste0(names(x)[length(names(x))], "~")
for (j in 1:length(a)) {
frm = paste0(frm, a[j], "+")
}
frm = substr(frm, 1, nchar(frm)-1) # remove last character
print(frm)
# build model
a = append(a, names(x)[length(names(x))])
mod = rpart(frm, xSample[, a])
# append to result ls
ls[[idx]] = mod
}
return(ls)
}
# Part 2 - predicting new instances
predictIns = function(ls, x) {
# ls is the list of random forest models
# x is the test data
# Store the prediction in data frame
predsDf = data.frame(matrix(ncol = length(ls), nrow = nrow(x)))
# set the column names
cols = c()
for (i in 1:length(ls)) {
cols = c(cols, paste("mod", i))
}
colnames(predsDf) = cols
# perform predictions
for(i in 1:length(ls)) {
pred = predict(ls[[i]], x, type="vector")
predsDf[i] = pred
}
# label predictions
for(i in 1:ncol(predsDf)) {
ind = predsDf[, i] <= 0.5
predsDf[ind, i] = -1
predsDf[!ind, i] = 1
}
# calculate majority vote
sum = rowSums(predsDf)
output = sign(sum)
# add sum, output column to predictions data frame
predsDf["sum"] = sum
predsDf["output"] = output
return(predsDf)
}
# load the data set
trainDs = read.table("hw06dataTrain.txt", header = TRUE)
testDs = read.table("hw06dataTest.txt", header = TRUE)
# get the models
lsMods = randomForestMods(x = trainDs, t = 21, n = 3000, d = 3)
# predict the new instances
resPredictIns1 = predictIns(ls = lsMods, x = testDs)
print(resPredictIns1)
View(resPredictIns)
View(resPredictIns)
# Part 1 - learning the model
randomForestMods = function(x, t, n, d) {
# x is training data
# t is number of trees to build
# n is number of instances to select for each tree
# d is number of attributes to use
ls = list() # rpart models
for (idx in 1:t) {
# randomly selected with replacement
xSample = x[sample(nrow(x), n, replace = TRUE),]
# attributes randomly selected without replacement
a = sample(names(x)[-length(names(x))], d, replace = FALSE)
# a = sort(a)
# build formula
frm = paste0(names(x)[length(names(x))], "~")
for (j in 1:length(a)) {
frm = paste0(frm, a[j], "+")
}
frm = substr(frm, 1, nchar(frm)-1) # remove last character
print(frm)
# build model
a = append(a, names(x)[length(names(x))])
mod = rpart(frm, xSample[, a])
# append to result ls
ls[[idx]] = mod
}
return(ls)
}
# Part 2 - predicting new instances
predictIns = function(ls, x) {
# ls is the list of random forest models
# x is the test data
# Store the prediction in data frame
predsDf = data.frame(matrix(ncol = length(ls), nrow = nrow(x)))
# set the column names
cols = c()
for (i in 1:length(ls)) {
cols = c(cols, paste("mod", i))
}
colnames(predsDf) = cols
# perform predictions
for(i in 1:length(ls)) {
pred = predict(ls[[i]], x, type="vector")
predsDf[i] = pred
}
# label predictions
for(i in 1:ncol(predsDf)) {
ind = predsDf[, i] <= 0.5
predsDf[ind, i] = -1
predsDf[!ind, i] = 1
}
# calculate majority vote
sum = rowSums(predsDf)
output = sign(sum)
# add sum, output column to predictions data frame
predsDf["sum"] = sum
predsDf["output"] = output
return(predsDf)
}
# load the data set
trainDs = read.table("hw06dataTrain.txt", header = TRUE)
testDs = read.table("hw06dataTest.txt", header = TRUE)
# get the models
lsMods = randomForestMods(x = trainDs, t = 21, n = 3000, d = 3)
# predict the new instances
resPredictIns = predictIns(ls = lsMods, x = testDs)
print(resPredictIns)
View(resPredictIns)
View(resPredictIns)
setwd("~/Documents/GVSU/cis-635-knowledge-discovery-and-data-mining/homework08")
setwd("~/Documents/GVSU/cis-635-knowledge-discovery-and-data-mining/homework07")
x = read.table("hw06dataTrain.txt", head = True)
x = read.table("hw06dataTrain.txt", head = TRUE)
summary(x)
x
head(x)
x[1,]
x[, "var3"]
x[, c("var3")]
x[ x$class == 1,]
x[ x$class == 1,]
colnames(x)
mean(x$var4)
mean(x[, "var4"])
min(x[, "var4"])
min(x$var4)
count(x[x$class ==1])
nrow(x[x$class ==1])
nrow(x[x$class ==1,])
nrow(x[x$class ==0,])
length(x[x$class ==0,])
x[1,]
mean(x$class[x$class == 1])
mean(x$class[x$class == 1,])
x$class
x[x$class == 1, "class"]
x[x$var3 > 30, "var3"]
mean(x[x$var3 > 30, "var3"])
x$class == 1
x[x$class == 1 ,c("var1, var2")]
x[x$class == 1 ,c("var1, var2")]
x[ ,c("var1, var2")]
x[ ,c("var1, var2")]
x
x[,c("var1")]
x[,c("var1", "var2")]
x[x$class == 1,c("var1", "var2")]
x[x$class == 1,c("var1", "var2")]
